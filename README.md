# âš¡ PulseAI - AI Energy & Hardware Profiler

> Intelligent hardware-aware profiling system that analyzes AI workload execution and recommends the most efficient compute backend based on performance, stability, and energy efficiency.

---

## ğŸš€ Overview

Modern AI workloads are typically optimized for **maximum performance**, not **maximum efficiency**.

However, real-world deployments - especially on **AI PCs, edge devices, and heterogeneous hardware systems** - require intelligent decisions about **where** an AI workload should run.

**PulseAI** is a production-style AI profiling framework that:

âœ… Profiles AI workloads across hardware backends  
âœ… Collects real-time system telemetry  
âœ… Models efficiency & sustainability metrics  
âœ… Detects execution stability  
âœ… Generates hardware recommendations  
âœ… Produces cryptographically verifiable experiment reports  

Instead of asking:

> *â€œWhich hardware is fastest?â€*

PulseAI answers:

> **â€œWhich hardware executes this AI workload most efficiently?â€**

---

## ğŸ¯ Problem Statement

AI systems today face:

- Increasing energy consumption
- Inefficient hardware utilization
- Blind backend selection (CPU vs GPU)
- Lack of sustainability-aware AI execution
- No transparent benchmarking evidence

Industries and hardware vendors require tools that can **intelligently match AI workloads to compute resources**.

PulseAI addresses this gap.

---

## ğŸ§  Key Idea

PulseAI treats AI execution as an **observable experiment**.
```bash

AI Workload
â†“
Hardware Backend
â†“
Real-Time Telemetry Sampling
â†“
Statistical Analysis
â†“
Efficiency Modeling
â†“
Backend Recommendation
```

---

## ğŸ— System Architecture

```bash
pulseai/
â”‚
â”œâ”€â”€ CLI Interface
â”œâ”€â”€ Experiment Orchestrator
â”œâ”€â”€ Hardware Abstraction Layer
â”‚ â”œâ”€â”€ CPU Backend
â”‚ â””â”€â”€ GPU Backend
â”‚
â”œâ”€â”€ Metrics Engine
â”‚ â”œâ”€â”€ CPU Telemetry
â”‚ â”œâ”€â”€ GPU Telemetry
â”‚ â””â”€â”€ Real-Time Sampler
â”‚
â”œâ”€â”€ AI Workloads
â”‚ â””â”€â”€ Transformer Text Inference
â”‚
â”œâ”€â”€ Analyzer
â”œâ”€â”€ Recommendation Engine
â”œâ”€â”€ Integrity Layer
â””â”€â”€ Reporting System
```

---

## âš™ï¸ Features

### Hardware-Aware AI Profiling
- CPU / GPU backend execution
- Extensible accelerator architecture
- Vendor-neutral design

### Real-Time Telemetry
- CPU utilization monitoring
- Memory pressure tracking
- GPU utilization proxy
- Time-series sampling

### Efficiency Modeling
PulseAI evaluates:

- Throughput (tokens/sec)
- Stability score
- Energy-per-token proxy
- Efficiency score

### Intelligent Recommendation Engine
Automatically recommends optimal backend based on:

- Sustainability
- Performance
- Execution stability

### Verifiable Experiment Reports
Each experiment generates:

- JSON audit artifact
- CSV performance summary
- Integrity fingerprint (SHA256)

Tampering becomes detectable.

---

## ğŸ¤– AI Workload

PulseAI profiles real transformer inference:

- Model: **DistilGPT2**
- Task: Text generation
- Metric: Tokens generated
- Deterministic execution

This represents modern LLM inference workloads.

---

## ğŸ“Š Example Output

```bash
========== PulseAI Recommendation ==========
Recommended Backend : CPU
Mode : sustainability
Efficiency Score : 0.90
Stability Score : 0.98
Report Saved : reports/pulseai-xxxx.json
```

---

## ğŸ§ª Experimental Results
```bash
| Run | Throughput | Efficiency | Stability |
|----|----|----|----|
| Run 1 | 53.95 tok/s | 0.84 | 0.94 |
| Run 2 | 55.16 tok/s | 0.90 | 0.98 |
```
PulseAI identified CPU execution as the most sustainable backend in the tested environment.

---

## ğŸ›  Installation

### 1ï¸. Clone Repository

```bash
git clone https://github.com/<your-username>/PulseAI.git
cd PulseAI
```
### 2ï¸. Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate
```
### 3ï¸. Install Dependencies
```bash
pip install torch transformers psutil python-dotenv
```
### â–¶ï¸ Running PulseAI
Run Single Backend Profiling
```bash
python -m pulseai.cli run --backend cpu
```
Cross Backend Comparison
```bash
python -m pulseai.cli compare --backends cpu gpu
```
### ğŸ“ Generated Reports
```bash
reports/
â”œâ”€â”€ pulseai-xxxx.json
â””â”€â”€ pulseai-xxxx.csv
```

#### Reports contain:

- experiment metadata

- efficiency metrics

- backend recommendation

- integrity hash
---

### ğŸ” Integrity Verification

#### Each report includes:
```bash
"integrity": {
  "hash_algorithm": "sha256",
  "fingerprint": "..."
}
```

#### Ensuring experiment authenticity.
---

### ğŸŒ± Sustainable AI Focus

#### PulseAI promotes:

- Energy-aware inference

- Efficient hardware utilization

- Responsible AI deployment

- Edge & AI PC optimization
---

### ğŸ§© Extensibility

#### Future backends can be added easily:

- `AMDNPUBackend`
- `EdgeAcceleratorBackend`
- `ROCmBackend`
- `FPGABackend`

#### No redesign required.
---

### ğŸ¯ AMD Slingshot Alignment

#### PulseAI directly supports:

- Heterogeneous compute optimization
- AI PC ecosystem
- Edge AI deployment
- Sustainable AI execution
- Hardware-aware AI workloads
---

### ğŸš€ Future Work

- Native AMD ROCm telemetry

- NPU backend integration

- Power sensor integration

- Multi-node profiling

- Auto workload scheduling
---

### ğŸ‘¨â€ğŸ’» Author

#### Pranay Sharma

#### AI Systems & Intelligent Infrastructure Enthusiast
---

### ğŸ“œ License

MIT License